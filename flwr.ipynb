{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you're on Python > 3.8\n",
    "# !pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-12-06 16:16:06,199\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import flwr as fl\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import Context\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Pre Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘.kaggle’: File exists\n",
      "mkdir: cannot create directory ‘.kaggle/data’: File exists\n",
      "compass.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!mkdir '.kaggle'\n",
    "!mkdir '.kaggle/data'\n",
    "\n",
    "with open(\".kaggle/kaggle.json\", 'a+') as f:\n",
    "    f.write('{\"username\":\"rajaxarcmu\",\"key\":\"68d40c5e38e1c786ab57736bc5c9b2cb\"}')\n",
    "    \n",
    "!chmod 600 '.kaggle/kaggle.json'\n",
    "!kaggle datasets download -d 'danofer/compass'\n",
    "!unzip -qo compass.zip -d '.kaggle/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compas-scores-raw.csv\tcox-violent-parsed_filt.csv\n",
      "cox-violent-parsed.csv\tpropublicaCompassRecividism_data_fairml.csv\n"
     ]
    }
   ],
   "source": [
    "!ls .kaggle/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6172, 12)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('.kaggle/data/propublicaCompassRecividism_data_fairml.csv/propublica_data_for_fairml.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['caucasian'] = ((df['African_American'] + df['Asian'] + df['Hispanic'] + df['Native_American'] + df['Other']) == 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 10\n",
    "# REPRESENTS SILO'D ORGANIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from flwr_datasets.partitioner import DirichletPartitioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (123) was not satisfied for alpha ([0.5]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (123) was not satisfied for alpha ([0.5]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (123) was not satisfied for alpha ([0.5]) after 2 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (123) was not satisfied for alpha ([0.5]) after 3 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (123) was not satisfied for alpha ([0.5]) after 4 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (123) was not satisfied for alpha ([0.5]) after 5 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (123) was not satisfied for alpha ([0.5]) after 6 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainset, testset = train_test_split(df, test_size=0.2)\n",
    "batch_size = 32\n",
    "\n",
    "ds = Dataset.from_pandas(trainset)\n",
    "\n",
    "partitioner = DirichletPartitioner(\n",
    "    num_partitions=NUM_CLIENTS,\n",
    "    partition_by=\"caucasian\",\n",
    "    alpha=0.5,\n",
    "    min_partition_size=(len(trainset) // (4 * NUM_CLIENTS)),\n",
    "    self_balancing=True,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "partitioner.dataset = ds\n",
    "datasets = []\n",
    "for i in range(NUM_CLIENTS):\n",
    "    curr_partition = partitioner.load_partition(i)\n",
    "    datasets.append(curr_partition.to_pandas())\n",
    "\n",
    "train_loaders = []\n",
    "val_loaders = []\n",
    "\n",
    "feature_columns = ['Number_of_Priors', 'score_factor','Age_Above_FourtyFive', 'Age_Below_TwentyFive', 'Misdemeanor']\n",
    "\n",
    "for ds in datasets:\n",
    "    train_x = ds[feature_columns].values\n",
    "    train_y = ds['Two_yr_Recidivism'].values\n",
    "    sensitive_feature = ds['caucasian'].values\n",
    "\n",
    "    train_x, val_x, train_y, val_y, sensitive_train, sensitive_val = train_test_split(\n",
    "        train_x, train_y, sensitive_feature, test_size=0.25, shuffle=True, stratify=train_y, random_state=42\n",
    "    )\n",
    "    \n",
    "    train_x_tensor = torch.from_numpy(train_x).float()\n",
    "    train_y_tensor = torch.from_numpy(train_y).float()\n",
    "    sensitive_train_tensor = torch.from_numpy(sensitive_train).float()\n",
    "\n",
    "    valid_x_tensor = torch.from_numpy(val_x).float()\n",
    "    valid_y_tensor = torch.from_numpy(val_y).float()\n",
    "    sensitive_val_tensor = torch.from_numpy(sensitive_val).float()\n",
    "\n",
    "    # Create TensorDataset and DataLoader, including the sensitive attribute\n",
    "    train_dataset = TensorDataset(train_x_tensor, train_y_tensor, sensitive_train_tensor)\n",
    "    valid_dataset = TensorDataset(valid_x_tensor, valid_y_tensor, sensitive_val_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(valid_dataset, batch_size=batch_size)\n",
    "\n",
    "    train_loaders.append(train_loader)\n",
    "    val_loaders.append(val_loader)\n",
    "\n",
    "# For test data\n",
    "test_x = testset[feature_columns].values\n",
    "test_y = testset['Two_yr_Recidivism'].values\n",
    "sensitive_test = testset['caucasian'].values\n",
    "\n",
    "test_x_tensor = torch.from_numpy(test_x).float()\n",
    "test_y_tensor = torch.from_numpy(test_y).float()\n",
    "sensitive_test_tensor = torch.from_numpy(sensitive_test).float()\n",
    "\n",
    "test_dataset = TensorDataset(test_x_tensor, test_y_tensor, sensitive_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaselineNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(5, 16)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "def compute_eod(preds, labels, sensitive_feature):\n",
    "    preds_binary = (preds >= 0.5).float()\n",
    "    y_true_mask = (labels == 1).view(-1)\n",
    "\n",
    "    p_a0 = preds_binary[y_true_mask & (sensitive_feature == 0)].mean().item()\n",
    "    p_a1 = preds_binary[y_true_mask & (sensitive_feature == 1)].mean().item()\n",
    "\n",
    "    eod = p_a0 - p_a1\n",
    "    return eod\n",
    "\n",
    "def train(net, trainloader, epochs, verbose=True):\n",
    "    \"\"\"\n",
    "    Train Network on Training Set\n",
    "    \"\"\"\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        all_preds, all_labels, all_sensitives = [], [], []\n",
    "        \n",
    "        for inputs, labels, sensitive_features in trainloader:\n",
    "            inputs, labels, sensitive_features = inputs.to(DEVICE), labels.to(DEVICE), sensitive_features.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            labels = labels.view(-1, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * inputs.size(0)\n",
    "            predicted = (outputs >= 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Append predictions and sensitive data for EOD computation\n",
    "            all_preds.append(outputs.detach().cpu())\n",
    "            all_labels.append(labels.detach().cpu())\n",
    "            all_sensitives.append(sensitive_features.cpu())\n",
    "        \n",
    "        # Compute EOD at the end of the epoch\n",
    "        all_preds = torch.cat(all_preds)\n",
    "        all_labels = torch.cat(all_labels)\n",
    "        all_sensitives = torch.cat(all_sensitives)\n",
    "        \n",
    "        eod = compute_eod(all_preds, all_labels, all_sensitives)\n",
    "        \n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f} - Acc: {epoch_acc:.4f} - EOD: {eod:.4f}\")\n",
    "\n",
    "def test(net, testloader, verbose=True):\n",
    "    criterion = nn.BCELoss()\n",
    "    net.eval()\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    all_preds, all_labels, all_sensitives = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, sensitive_features in testloader:\n",
    "            inputs, labels, sensitive_features = inputs.to(DEVICE), labels.to(DEVICE), sensitive_features.to(DEVICE)\n",
    "            outputs = net(inputs)\n",
    "            labels = labels.view(-1, 1)\n",
    "            loss += criterion(outputs, labels).item() * inputs.size(0)\n",
    "            predicted = (outputs >= 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Append predictions and sensitive data for EOD computation\n",
    "            all_preds.append(outputs.detach().cpu())\n",
    "            all_labels.append(labels.detach().cpu())\n",
    "            all_sensitives.append(sensitive_features.cpu())\n",
    "    \n",
    "    # Compute EOD at the end of testing\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    all_sensitives = torch.cat(all_sensitives)\n",
    "    \n",
    "    eod = compute_eod(all_preds, all_labels, all_sensitives)\n",
    "    \n",
    "    loss /= len(testloader.dataset)\n",
    "    acc = correct / total\n",
    "    if verbose:\n",
    "        print(f\"Test Loss: {loss:.4f} - Acc: {acc:.4f} - EOD: {eod:.4f}\")\n",
    "    return loss, acc, eod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centralized Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaselineNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(NUM_CLIENTS):\n",
    "    train_loader = train_loaders[i]\n",
    "    val_loader = val_loaders[i]\n",
    "    model = model.to(DEVICE)\n",
    "    epochs = 10\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train(model, train_loader, 1, verbose=False)\n",
    "        loss, acc, eod = test(model, val_loader, verbose=False)\n",
    "\n",
    "    loss, acc, eod = test(model, test_loader, verbose=False)\n",
    "    print(f\"Client {i} - Test Loss: {loss:.4f} - Acc: {acc:.4f} - EOD: {eod:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness Eval - Centralized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning with Flower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (61) was not satisfied for alpha ([0.5]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (61) was not satisfied for alpha ([0.5]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (61) was not satisfied for alpha ([0.5]) after 2 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (61) was not satisfied for alpha ([0.5]) after 3 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (61) was not satisfied for alpha ([0.5]) after 4 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (61) was not satisfied for alpha ([0.5]) after 5 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (61) was not satisfied for alpha ([0.5]) after 6 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n",
      "  warnings.warn(\n",
      "\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=10, no round_timeout\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [INIT]\n",
      "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
      "\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n",
      "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 25.511822222135006, {'centralized_accuracy': 0.5562753036437247, 'eod': 0.07481992244720459, 'indf': 0.5877457112073898}\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5562753036437247 - Test Loss: 25.511822222135006 - EOD: 0.07481992244720459 - IndFair: 0.5877457112073898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[36m(ClientAppActor pid=259346)\u001b[0m /home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (61) was not satisfied for alpha ([0.5]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n",
      "\u001b[36m(ClientAppActor pid=259346)\u001b[0m   warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=259346)\u001b[0m Avg Train Loss: 0.7525189995765686 - EOD: nan - Accuracy: 0.5849673202614379 - Ind Fair: 2.1438612937927246\n",
      "\u001b[36m(ClientAppActor pid=259348)\u001b[0m Avg Train Loss: 0.8499585926532746 - EOD: 0.17518247663974762 - Accuracy: 0.5511551155115512 - Ind Fair: 1.4491927474737167\n",
      "\u001b[36m(ClientAppActor pid=259344)\u001b[0m Skipping batch with single class.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (1, 20.874681086112293, {'centralized_accuracy': 0.5417004048582996, 'eod': -0.006097560748457909, 'indf': 0.05039329081773758}, 18.389092947996687)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=259344)\u001b[0m Skipping batch with single class.\n",
      "LOGG: RESULTS\n",
      "{'indfair': 0.6789228767156601, 'acc': 0.5802469135802469, 'eod': nan, 'train_loss': 0.7219948172569275, 'id': 0} 567\n",
      "{'indfair': 1.2689789533615112, 'acc': 0.5267857142857143, 'eod': 0.13333334028720856, 'train_loss': 0.7152193561196327, 'id': 9} 225\n",
      "{'indfair': 0.7461724728345871, 'acc': 0.6334563345633456, 'eod': 0.029304031282663345, 'train_loss': 0.7000736342026637, 'id': 8} 813\n",
      "{'indfair': 4.628687560558319, 'acc': 0.5128205128205128, 'eod': nan, 'train_loss': 1.0967946648597717, 'id': 1} 78\n",
      "{'indfair': 2.1438612937927246, 'acc': 0.5849673202614379, 'eod': nan, 'train_loss': 0.7525189995765686, 'id': 4} 306\n",
      "{'indfair': 1.4176048934459686, 'acc': 0.525, 'eod': -0.0035682469606399536, 'train_loss': 0.7563809156417847, 'id': 5} 165\n",
      "{'indfair': 0.889412134885788, 'acc': 0.6103286384976526, 'eod': 0.010504201054573059, 'train_loss': 0.7439420563834054, 'id': 6} 213\n",
      "{'indfair': 0.6743005514144897, 'acc': 0.5518018018018018, 'eod': nan, 'train_loss': 0.7410016783646175, 'id': 3} 444\n",
      "{'indfair': 0.9314579963684082, 'acc': 0.6024305555555556, 'eod': 0.005493296310305595, 'train_loss': 0.7581419414944119, 'id': 7} 576\n",
      "{'indfair': 1.4491927474737167, 'acc': 0.5511551155115512, 'eod': 0.17518247663974762, 'train_loss': 0.8499585926532746, 'id': 2} 303\n",
      "============= LOGGG USING FEDAVG WEIGHTS\n",
      "============= LOGGG WEIGHT RESULTS\n",
      "[0, 9, 8, 1, 4, 5, 6, 3, 7, 2]\n",
      "{0: 0.15365853658536585, 9: 0.06097560975609756, 8: 0.22032520325203253, 1: 0.02113821138211382, 4: 0.08292682926829269, 5: 0.044715447154471545, 6: 0.05772357723577236, 3: 0.12032520325203253, 7: 0.15609756097560976, 2: 0.08211382113821138}\n",
      "Test Accuracy: 0.5417004048582996 - Test Loss: 20.874681086112293 - EOD: -0.006097560748457909 - IndFair: 0.05039329081773758\n",
      "\u001b[36m(ClientAppActor pid=259348)\u001b[0m Test Accuracy: 0.5588235294117647 - Test Loss: 17.27313843369484 - EOD: nan - IndFair: 0.024532293900847435\n",
      "\u001b[36m(ClientAppActor pid=259350)\u001b[0m Test Accuracy: 0.5714285714285714 - Test Loss: 14.897182017564774 - EOD: 0.0 - IndFair: 0.056871123961173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (2, 20.18538178388889, {'centralized_accuracy': 0.5838056680161944, 'eod': 0.09194758534431458, 'indf': 0.1680736318230629}, 22.509178981999867)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGG: RESULTS\n",
      "{'indfair': 0.14595678448677063, 'acc': 0.5512820512820513, 'eod': nan, 'train_loss': 0.6856584747632345, 'id': 1} 78\n",
      "{'indfair': 0.7835009098052979, 'acc': 0.6614077669902912, 'eod': 0.08684621751308441, 'train_loss': 0.6290869449193661, 'id': 8} 824\n",
      "{'indfair': 0.5870436131954193, 'acc': 0.6749116607773852, 'eod': nan, 'train_loss': 0.6289893156952329, 'id': 0} 566\n",
      "{'indfair': 0.6424995958805084, 'acc': 0.6460331299040977, 'eod': 0.03992900252342224, 'train_loss': 0.6472555465168424, 'id': 2} 1147\n",
      "{'indfair': 0.7155047655105591, 'acc': 0.6701388888888888, 'eod': 0.14055301249027252, 'train_loss': 0.622628528820841, 'id': 7} 578\n",
      "{'indfair': 0.40479592978954315, 'acc': 0.6319444444444444, 'eod': -0.021276595070958138, 'train_loss': 0.6386238217353821, 'id': 5} 144\n",
      "{'indfair': 0.7712594568729401, 'acc': 0.6405228758169934, 'eod': 0.2054794579744339, 'train_loss': 0.6502391338348389, 'id': 4} 306\n",
      "{'indfair': 0.6056909263134003, 'acc': 0.5868544600938967, 'eod': 0.0, 'train_loss': 0.6658220291137695, 'id': 6} 213\n",
      "{'indfair': 0.7571901082992554, 'acc': 0.65625, 'eod': 0.31192660331726074, 'train_loss': 0.5623176395893097, 'id': 9} 226\n",
      "{'indfair': 0.0475644338876009, 'acc': 0.6065573770491803, 'eod': 0.06976744532585144, 'train_loss': 0.6762120425701141, 'id': 3} 122\n",
      "============= LOGGG WEIGHT RESULTS\n",
      "[1, 8, 0, 2, 7, 5, 4, 6, 9, 3]\n",
      "{0: 0.15492536554331096, 9: 0.05591408665759898, 8: 0.22452243533824398, 1: 0.02240504034005893, 4: 0.0841936582262378, 5: 0.04562545141635266, 6: 0.060040826299174774, 3: 0.12159203220997764, 7: 0.15791371956458541, 2: 0.07286738440445889}\n",
      "Test Accuracy: 0.5838056680161944 - Test Loss: 20.18538178388889 - EOD: 0.09194758534431458 - IndFair: 0.1680736318230629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=259348)\u001b[0m /home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (61) was not satisfied for alpha ([0.5]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\u001b[32m [repeated 146x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259348)\u001b[0m   warnings.warn(\u001b[32m [repeated 146x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=259347)\u001b[0m Avg Train Loss: 0.6856584747632345 - EOD: nan - Accuracy: 0.5512820512820513 - Ind Fair: 0.14595678448677063\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259347)\u001b[0m Avg Train Loss: 0.622628528820841 - EOD: 0.14055301249027252 - Accuracy: 0.6701388888888888 - Ind Fair: 0.7155047655105591\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259347)\u001b[0m Skipping batch with single class.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259348)\u001b[0m Test Accuracy: 0.5369127516778524 - Test Loss: 18.32051740884781 - EOD: nan - IndFair: 0.23988544195890427\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259344)\u001b[0m Test Accuracy: 0.6197916666666666 - Test Loss: 20.000264803568523 - EOD: 0.03404255211353302 - IndFair: 0.2669340893626213\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (3, 20.10611885633224, {'centralized_accuracy': 0.5862348178137652, 'eod': 0.08585002273321152, 'indf': 0.18071679770946503}, 26.69911534199491)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGG: RESULTS\n",
      "{'indfair': 0.7102959901094437, 'acc': 0.6625, 'eod': 0.14814814925193787, 'train_loss': 0.49400139848391217, 'id': 8} 161\n",
      "{'indfair': 0.40838822722435, 'acc': 0.6072607260726073, 'eod': 0.053357310593128204, 'train_loss': 0.6540331423282624, 'id': 2} 303\n",
      "{'indfair': 0.4851606488227844, 'acc': 0.6085011185682326, 'eod': nan, 'train_loss': 0.6620831106390271, 'id': 3} 447\n",
      "{'indfair': 1.245438039302826, 'acc': 0.6326530612244898, 'eod': 0.10326086916029453, 'train_loss': 0.6469068884849548, 'id': 5} 147\n",
      "{'indfair': 0.7909272313117981, 'acc': 0.7088607594936709, 'eod': 0.4107142835855484, 'train_loss': 0.6271380543708801, 'id': 6} 158\n",
      "{'indfair': 0.5686902552843094, 'acc': 0.5128205128205128, 'eod': nan, 'train_loss': 0.7244950334231058, 'id': 1} 78\n",
      "{'indfair': 0.5072325617074966, 'acc': 0.6300174520069808, 'eod': nan, 'train_loss': 0.6658645669619242, 'id': 0} 573\n",
      "{'indfair': 1.1306018233299255, 'acc': 0.6525096525096525, 'eod': 0.7592592537403107, 'train_loss': 0.6200263500213623, 'id': 7} 259\n",
      "{'indfair': 0.5449792295694351, 'acc': 0.6537216828478964, 'eod': -0.09627330303192139, 'train_loss': 0.6621942579746246, 'id': 4} 309\n",
      "{'indfair': 0.6558531820774078, 'acc': 0.6339285714285714, 'eod': nan, 'train_loss': 0.5788427889347076, 'id': 9} 225\n",
      "============= LOGGG WEIGHT RESULTS\n",
      "[8, 2, 3, 5, 6, 1, 0, 7, 4, 9]\n",
      "{0: 0.1548234187758914, 9: 0.041283982439920666, 8: 0.2324003697009833, 1: 0.022303093572639356, 4: 0.08020826854284217, 5: 0.043395845141837266, 6: 0.059938879531755196, 3: 0.1284668299751432, 7: 0.16042097442960593, 2: 0.07675833788938154}\n",
      "Test Accuracy: 0.5862348178137652 - Test Loss: 20.10611885633224 - EOD: 0.08585002273321152 - IndFair: 0.18071679770946503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[36m(ClientAppActor pid=259348)\u001b[0m /home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (61) was not satisfied for alpha ([0.5]) after 6 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\u001b[32m [repeated 186x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259348)\u001b[0m   warnings.warn(\u001b[32m [repeated 186x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=259350)\u001b[0m Avg Train Loss: 0.5788427889347076 - EOD: nan - Accuracy: 0.6339285714285714 - Ind Fair: 0.6558531820774078\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259346)\u001b[0m Avg Train Loss: 0.6624707182248434 - EOD: 0.24920635670423508 - Accuracy: 0.5967741935483871 - Ind Fair: 0.40064162015914917\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259349)\u001b[0m Skipping batch with single class.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259347)\u001b[0m Test Accuracy: 0.5733333333333334 - Test Loss: 16.27729578812917 - EOD: nan - IndFair: 0.106546301394701\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259349)\u001b[0m Test Accuracy: 0.5555555555555556 - Test Loss: 17.033319771289825 - EOD: 0.0 - IndFair: 0.5127481371164322\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (4, 20.09442985516328, {'centralized_accuracy': 0.605668016194332, 'eod': 0.14469224959611893, 'indf': 0.21142560988664627}, 30.83387390599819)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGG: RESULTS\n",
      "{'indfair': 0.38620422780513763, 'acc': 0.6923076923076923, 'eod': nan, 'train_loss': 0.6280746857325236, 'id': 1} 78\n",
      "{'indfair': 0.5646152496337891, 'acc': 0.6469864698646987, 'eod': 0.1254887655377388, 'train_loss': 0.6439977494569925, 'id': 8} 813\n",
      "{'indfair': 0.6841877698898315, 'acc': 0.6383928571428571, 'eod': nan, 'train_loss': 0.5736682042479515, 'id': 9} 225\n",
      "{'indfair': 0.5072833895683289, 'acc': 0.6437282229965157, 'eod': 0.012838691473007202, 'train_loss': 0.6559809048970541, 'id': 2} 1148\n",
      "{'indfair': 0.3994935005903244, 'acc': 0.6347826086956522, 'eod': 0.08398747444152832, 'train_loss': 0.6542434556917711, 'id': 0} 690\n",
      "{'indfair': 0.8908488750457764, 'acc': 0.7125, 'eod': 0.2816092036664486, 'train_loss': 0.6773794889450073, 'id': 6} 160\n",
      "{'indfair': 0.5758866369724274, 'acc': 0.6788194444444444, 'eod': 0.0909692794084549, 'train_loss': 0.6397855811648898, 'id': 7} 576\n",
      "{'indfair': 0.40064162015914917, 'acc': 0.5967741935483871, 'eod': 0.24920635670423508, 'train_loss': 0.6624707182248434, 'id': 3} 186\n",
      "{'indfair': 0.22530783712863922, 'acc': 0.6484848484848484, 'eod': 0.15521977096796036, 'train_loss': 0.6482358376185099, 'id': 5} 165\n",
      "{'indfair': 1.0786615312099457, 'acc': 0.6459016393442623, 'eod': 0.21568627655506134, 'train_loss': 0.6605281054973602, 'id': 4} 305\n",
      "============= LOGGG WEIGHT RESULTS\n",
      "[1, 8, 9, 2, 0, 6, 7, 3, 5, 4]\n",
      "{0: 0.15913038749465858, 9: 0.04559095115868783, 8: 0.24946185476054264, 1: 0.026610062291406524, 4: 0.0748879069584172, 5: 0.05802890077663389, 6: 0.05074375115795349, 3: 0.13277379869391037, 7: 0.116371349040328, 2: 0.08640103766746153}\n",
      "Test Accuracy: 0.605668016194332 - Test Loss: 20.09442985516328 - EOD: 0.14469224959611893 - IndFair: 0.21142560988664627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (5, 20.010937603620384, {'centralized_accuracy': 0.6283400809716599, 'eod': 0.14575137197971344, 'indf': 0.26947323977947235}, 34.95544405200053)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGG: RESULTS\n",
      "{'indfair': 0.7837035953998566, 'acc': 0.7407407407407407, 'eod': 0.3139534890651703, 'train_loss': 0.6114916631153652, 'id': 6} 216\n",
      "{'indfair': 0.5417304039001465, 'acc': 0.6776556776556777, 'eod': 0.12014183402061462, 'train_loss': 0.6375305813092452, 'id': 8} 819\n",
      "{'indfair': 0.38844315707683563, 'acc': 0.6424870466321243, 'eod': 0.18769368529319763, 'train_loss': 0.6445408683074149, 'id': 7} 579\n",
      "{'indfair': 0.5814871191978455, 'acc': 0.5714285714285714, 'eod': 0.20363637804985046, 'train_loss': 0.6728676915168762, 'id': 5} 147\n",
      "{'indfair': 0.3377790078520775, 'acc': 0.5914893617021276, 'eod': 0.20000000298023224, 'train_loss': 0.6874730288982391, 'id': 1} 235\n",
      "{'indfair': 0.9220851957798004, 'acc': 0.6367713004484304, 'eod': nan, 'train_loss': 0.6569051487105233, 'id': 3} 446\n",
      "{'indfair': 0.840386688709259, 'acc': 0.6568627450980392, 'eod': 0.3125, 'train_loss': 0.6315587103366852, 'id': 4} 306\n",
      "{'indfair': 0.5705111920833588, 'acc': 0.6690017513134852, 'eod': 0.08328060805797577, 'train_loss': 0.6382698863744736, 'id': 2} 1142\n",
      "{'indfair': 0.39256298542022705, 'acc': 0.6498257839721254, 'eod': nan, 'train_loss': 0.6470353504021963, 'id': 0} 574\n",
      "{'indfair': 2.1390307545661926, 'acc': 0.6460176991150443, 'eod': nan, 'train_loss': 0.650945708155632, 'id': 9} 226\n",
      "============= LOGGG WEIGHT RESULTS\n",
      "[6, 8, 7, 5, 1, 3, 4, 2, 0, 9]\n",
      "{0: 0.1637732260323516, 9: 0.04183504225222802, 8: 0.25745718567539766, 1: 0.022854153384946715, 4: 0.07386348677153995, 5: 0.06305113114846674, 6: 0.04312703825993751, 3: 0.12839737049211575, 7: 0.12171236807471368, 2: 0.08392899790830244}\n",
      "Test Accuracy: 0.6283400809716599 - Test Loss: 20.010937603620384 - EOD: 0.14575137197971344 - IndFair: 0.26947323977947235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=259348)\u001b[0m /home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (61) was not satisfied for alpha ([0.5]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\u001b[32m [repeated 168x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259348)\u001b[0m   warnings.warn(\u001b[32m [repeated 168x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=259349)\u001b[0m Avg Train Loss: 0.650945708155632 - EOD: nan - Accuracy: 0.6460176991150443 - Ind Fair: 2.1390307545661926\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259344)\u001b[0m Avg Train Loss: 0.6375305813092452 - EOD: 0.12014183402061462 - Accuracy: 0.6776556776556777 - Ind Fair: 0.5417304039001465\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259350)\u001b[0m Skipping batch with single class.\n",
      "\u001b[36m(ClientAppActor pid=259348)\u001b[0m Test Accuracy: 0.6274509803921569 - Test Loss: 15.019591271877289 - EOD: nan - IndFair: 0.4341113120317459\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259349)\u001b[0m Test Accuracy: 0.6494464944649446 - Test Loss: 19.00955718755722 - EOD: 0.13696061074733734 - IndFair: 0.4169203191995621\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=259350)\u001b[0m Skipping batch with single class.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (6, 20.123105781200604, {'centralized_accuracy': 0.594331983805668, 'eod': 0.08988984674215317, 'indf': 0.15418964251875877}, 39.079030112996406)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGG: RESULTS\n",
      "{'indfair': 0.4343412071466446, 'acc': 0.6538461538461539, 'eod': nan, 'train_loss': 0.6629364887873331, 'id': 1} 78\n",
      "{'indfair': 0.1895846724510193, 'acc': 0.6705426356589147, 'eod': 0.3662921413779259, 'train_loss': 0.6297911140653822, 'id': 7} 258\n",
      "{'indfair': 0.6394061148166656, 'acc': 0.6503267973856209, 'eod': nan, 'train_loss': 0.6400976657867432, 'id': 4} 306\n",
      "{'indfair': 0.872653603553772, 'acc': 0.6581196581196581, 'eod': 0.209090918302536, 'train_loss': 0.6659737676382065, 'id': 9} 117\n",
      "{'indfair': 0.5540635883808136, 'acc': 0.6524590163934426, 'eod': 0.14848144352436066, 'train_loss': 0.6477578341960907, 'id': 2} 305\n",
      "{'indfair': 1.1466274857521057, 'acc': 0.6919014084507042, 'eod': nan, 'train_loss': 0.6320860998498069, 'id': 0} 568\n",
      "{'indfair': 0.5758387595415115, 'acc': 0.6334563345633456, 'eod': 0.06358885020017624, 'train_loss': 0.6426736483207116, 'id': 8} 813\n",
      "{'indfair': 0.49138492345809937, 'acc': 0.6428571428571429, 'eod': nan, 'train_loss': 0.6164658188819885, 'id': 3} 450\n",
      "{'indfair': 0.19288897514343262, 'acc': 0.6275862068965518, 'eod': 0.0, 'train_loss': 0.659180736541748, 'id': 5} 145\n",
      "{'indfair': 0.9983717501163483, 'acc': 0.6923076923076923, 'eod': 0.779661014676094, 'train_loss': 0.6301944553852081, 'id': 6} 156\n",
      "============= LOGGG WEIGHT RESULTS\n",
      "[1, 7, 4, 9, 2, 0, 8, 3, 5, 6]\n",
      "{0: 0.15970477719077977, 9: 0.03776659341065621, 8: 0.2654029202358873, 1: 0.027209824194692506, 4: 0.06696915787930896, 5: 0.0670431644512507, 6: 0.03608736046118949, 3: 0.12432892165054393, 7: 0.12729867065316294, 2: 0.0881886098725282}\n",
      "Test Accuracy: 0.594331983805668 - Test Loss: 20.123105781200604 - EOD: 0.08988984674215317 - IndFair: 0.15418964251875877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[36m(ClientAppActor pid=259348)\u001b[0m /home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (61) was not satisfied for alpha ([0.5]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\u001b[32m [repeated 156x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259348)\u001b[0m   warnings.warn(\u001b[32m [repeated 156x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=259346)\u001b[0m Avg Train Loss: 0.6400976657867432 - EOD: nan - Accuracy: 0.6503267973856209 - Ind Fair: 0.6394061148166656\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259348)\u001b[0m Avg Train Loss: 0.6315774083137512 - EOD: 0.4097222164273262 - Accuracy: 0.6655737704918033 - Ind Fair: 0.9106156826019287\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259349)\u001b[0m Test Accuracy: 0.5789473684210527 - Test Loss: 15.938920418421427 - EOD: nan - IndFair: 0.16720420867204666\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259347)\u001b[0m Test Accuracy: 0.6666666666666666 - Test Loss: 12.124981562296549 - EOD: -0.1599999964237213 - IndFair: 0.3643249124288559\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (7, 19.963842173417408, {'centralized_accuracy': 0.6283400809716599, 'eod': 0.14575137197971344, 'indf': 0.2882625609636307}, 43.23569674499595)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGG: RESULTS\n",
      "{'indfair': 0.5377912819385529, 'acc': 0.6242424242424243, 'eod': 0.1325535997748375, 'train_loss': 0.6617749134699503, 'id': 5} 165\n",
      "{'indfair': 0.5747676491737366, 'acc': 0.6919642857142857, 'eod': nan, 'train_loss': 0.6357679452214923, 'id': 3} 448\n",
      "{'indfair': 0.36878784000873566, 'acc': 0.6794871794871795, 'eod': nan, 'train_loss': 0.6424461205800375, 'id': 1} 78\n",
      "{'indfair': 0.530191957950592, 'acc': 0.6875, 'eod': 0.05860652029514313, 'train_loss': 0.6224156274245336, 'id': 8} 816\n",
      "{'indfair': 0.9106156826019287, 'acc': 0.6655737704918033, 'eod': 0.4097222164273262, 'train_loss': 0.6315774083137512, 'id': 2} 305\n",
      "{'indfair': 0.8759768009185791, 'acc': 0.665, 'eod': 0.20046620070934296, 'train_loss': 0.616974971796337, 'id': 4} 600\n",
      "{'indfair': 0.8092678636312485, 'acc': 0.6517857142857143, 'eod': nan, 'train_loss': 0.6239054426550865, 'id': 9} 225\n",
      "{'indfair': 1.9182255268096924, 'acc': 0.6637168141592921, 'eod': nan, 'train_loss': 0.6879619277185864, 'id': 0} 565\n",
      "{'indfair': 0.69810751080513, 'acc': 0.6401384083044983, 'eod': 0.11588862538337708, 'train_loss': 0.6728814024674264, 'id': 7} 578\n",
      "{'indfair': 0.6320884525775909, 'acc': 0.7247706422018348, 'eod': 0.08674699068069458, 'train_loss': 0.5967223644256592, 'id': 6} 218\n",
      "============= LOGGG WEIGHT RESULTS\n",
      "[5, 3, 1, 8, 2, 4, 9, 0, 7, 6]\n",
      "{0: 0.1617318287886134, 9: 0.05022684053985809, 8: 0.2737888568537385, 1: 0.029236875792526134, 4: 0.06899620947714258, 5: 0.06907021604908432, 6: -0.00850940204696443, 3: 0.12635597324837755, 7: 0.12403879547482582, 2: 0.10506380582279788}\n",
      "Test Accuracy: 0.6283400809716599 - Test Loss: 19.963842173417408 - EOD: 0.14575137197971344 - IndFair: 0.2882625609636307\n",
      "\u001b[36m(ClientAppActor pid=259349)\u001b[0m Skipping batch with single class.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=259350)\u001b[0m Skipping batch with single class.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (8, 19.99332001270392, {'centralized_accuracy': 0.6639676113360324, 'eod': 0.20068994164466858, 'indf': 0.3448680192232132}, 47.35302303399658)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGG: RESULTS\n",
      "{'indfair': 0.9412790834903717, 'acc': 0.6731107205623902, 'eod': 0.16153845191001892, 'train_loss': 0.6262507753239738, 'id': 2} 1138\n",
      "{'indfair': 0.49944868683815, 'acc': 0.6915887850467289, 'eod': -0.06410256773233414, 'train_loss': 0.6422890084130424, 'id': 6} 214\n",
      "{'indfair': 0.368352010846138, 'acc': 0.71875, 'eod': 0.0867132768034935, 'train_loss': 0.523939311504364, 'id': 5} 165\n",
      "{'indfair': 0.7614003717899323, 'acc': 0.6781115879828327, 'eod': 0.22772277891635895, 'train_loss': 0.6610973849892616, 'id': 1} 233\n",
      "{'indfair': 0.5013117045164108, 'acc': 0.675, 'eod': 0.1600753292441368, 'train_loss': 0.5395071605841318, 'id': 8} 161\n",
      "{'indfair': 0.6315054893493652, 'acc': 0.679372197309417, 'eod': nan, 'train_loss': 0.6322943781103406, 'id': 3} 446\n",
      "{'indfair': 0.9347384870052338, 'acc': 0.6916299559471366, 'eod': -0.6551724076271057, 'train_loss': 0.64500592648983, 'id': 9} 227\n",
      "{'indfair': 0.8495832979679108, 'acc': 0.698943661971831, 'eod': nan, 'train_loss': 0.6144755184650421, 'id': 0} 568\n",
      "{'indfair': 0.6150097548961639, 'acc': 0.6799336650082919, 'eod': 0.04245525598526001, 'train_loss': 0.6371138315451773, 'id': 4} 603\n",
      "{'indfair': 0.8705995082855225, 'acc': 0.6798623063683304, 'eod': 0.21540600061416626, 'train_loss': 0.6156258771294042, 'id': 7} 581\n",
      "============= LOGGG WEIGHT RESULTS\n",
      "[2, 6, 5, 1, 8, 3, 9, 0, 4, 7]\n",
      "{0: 0.1608327268756381, 9: 0.04932773862688279, 8: 0.27875040697027753, 1: 0.02833777387955083, 4: 0.06813017055864741, 5: 0.0749954372240397, 6: -0.0007338048918702821, 3: 0.12545687133540226, 7: 0.13163051408892726, 2: 0.0832721653325044}\n",
      "Test Accuracy: 0.6639676113360324 - Test Loss: 19.99332001270392 - EOD: 0.20068994164466858 - IndFair: 0.3448680192232132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=259348)\u001b[0m /home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (61) was not satisfied for alpha ([0.5]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\u001b[32m [repeated 180x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259348)\u001b[0m   warnings.warn(\u001b[32m [repeated 180x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=259344)\u001b[0m Avg Train Loss: 0.6144755184650421 - EOD: nan - Accuracy: 0.698943661971831 - Ind Fair: 0.8495832979679108\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259350)\u001b[0m Avg Train Loss: 0.6156258771294042 - EOD: 0.21540600061416626 - Accuracy: 0.6798623063683304 - Ind Fair: 0.8705995082855225\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259348)\u001b[0m Test Accuracy: 0.6666666666666666 - Test Loss: 19.2263206243515 - EOD: nan - IndFair: 0.6837462484836578\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259344)\u001b[0m Test Accuracy: 0.6875 - Test Loss: 18.601953930324978 - EOD: 0.16885554790496826 - IndFair: 0.9234695732593536\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (9, 19.99785047922379, {'centralized_accuracy': 0.5797570850202429, 'eod': 0.08542637526988983, 'indf': 0.14665638655424118}, 51.50003291599569)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGG: RESULTS\n",
      "{'indfair': 0.6227264106273651, 'acc': 0.636986301369863, 'eod': -0.09777776896953583, 'train_loss': 0.6382525444030762, 'id': 5} 146\n",
      "{'indfair': 0.4446057975292206, 'acc': 0.6188340807174888, 'eod': nan, 'train_loss': 0.6664918575968061, 'id': 9} 223\n",
      "{'indfair': 0.7487339973449707, 'acc': 0.675, 'eod': 0.16923077404499054, 'train_loss': 0.5328327516714731, 'id': 8} 161\n",
      "{'indfair': 0.3456682711839676, 'acc': 0.6197183098591549, 'eod': 0.1411764733493328, 'train_loss': 0.6604372348104205, 'id': 6} 213\n",
      "{'indfair': 0.8456568419933319, 'acc': 0.6782608695652174, 'eod': 0.1262562870979309, 'train_loss': 0.6243273290720853, 'id': 0} 690\n",
      "{'indfair': 0.688570499420166, 'acc': 0.6850921273031826, 'eod': 0.22439759969711304, 'train_loss': 0.6430043985969142, 'id': 4} 597\n",
      "{'indfair': 0.37801460921764374, 'acc': 0.6025641025641025, 'eod': nan, 'train_loss': 0.6256801883379618, 'id': 1} 78\n",
      "{'indfair': 0.530886098742485, 'acc': 0.6510416666666666, 'eod': 0.11234337091445923, 'train_loss': 0.6125100223641646, 'id': 7} 577\n",
      "{'indfair': 0.6451139152050018, 'acc': 0.7043010752688172, 'eod': 0.06321839243173599, 'train_loss': 0.6203160583972931, 'id': 3} 186\n",
      "{'indfair': 0.7026982307434082, 'acc': 0.6842105263157895, 'eod': 0.24911972880363464, 'train_loss': 0.6261591613292694, 'id': 2} 304\n",
      "============= LOGGG WEIGHT RESULTS\n",
      "[5, 9, 8, 6, 0, 4, 1, 7, 3, 2]\n",
      "{0: 0.1748689541465989, 9: -0.0021532748648669733, 8: 0.2802718236791045, 1: 0.023094445621155636, 4: 0.08141359459336212, 5: 0.08385305917693105, 6: 0.00689216560585711, 3: 0.13949309860636305, 7: 0.12761886366075134, 2: 0.0846472697747432}\n",
      "Test Accuracy: 0.5797570850202429 - Test Loss: 19.99785047922379 - EOD: 0.08542637526988983 - IndFair: 0.14665638655424118\n",
      "\u001b[36m(ClientAppActor pid=259347)\u001b[0m Skipping batch with single class.\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
      "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 10)\n",
      "\u001b[36m(ClientAppActor pid=259348)\u001b[0m /home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (61) was not satisfied for alpha ([0.5]) after 6 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\u001b[32m [repeated 180x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259348)\u001b[0m   warnings.warn(\u001b[32m [repeated 180x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=259348)\u001b[0m Avg Train Loss: 0.6664918575968061 - EOD: nan - Accuracy: 0.6188340807174888 - Ind Fair: 0.4446057975292206\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259348)\u001b[0m Avg Train Loss: 0.5994156002998352 - EOD: 0.4285714328289032 - Accuracy: 0.6794871794871795 - Ind Fair: 0.6968524381518364\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259348)\u001b[0m Test Accuracy: 0.5333333333333333 - Test Loss: 15.852348546187082 - EOD: nan - IndFair: 0.12353206053376198\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259349)\u001b[0m Test Accuracy: 0.6288659793814433 - Test Loss: 16.873355218342372 - EOD: -0.00555555522441864 - IndFair: 0.2835659384727478\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      fit progress: (10, 20.125912505846756, {'centralized_accuracy': 0.6720647773279352, 'eod': 0.20494157075881958, 'indf': 0.40790942311286926}, 54.64603922099923)\n",
      "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGG: RESULTS\n",
      "{'indfair': 0.3939465284347534, 'acc': 0.6484848484848484, 'eod': 0.0892857015132904, 'train_loss': 0.6244756976763407, 'id': 5} 165\n",
      "{'indfair': 0.6376438438892365, 'acc': 0.689594356261023, 'eod': nan, 'train_loss': 0.6345612903436025, 'id': 0} 567\n",
      "{'indfair': 0.44157856702804565, 'acc': 0.6990740740740741, 'eod': 0.18333332985639572, 'train_loss': 0.6119434152330671, 'id': 6} 216\n",
      "{'indfair': 0.6968524381518364, 'acc': 0.6794871794871795, 'eod': 0.4285714328289032, 'train_loss': 0.5994156002998352, 'id': 1} 234\n",
      "{'indfair': 0.5711197853088379, 'acc': 0.6495652173913044, 'eod': 0.01862068474292755, 'train_loss': 0.6519792758756213, 'id': 2} 1150\n",
      "{'indfair': 0.7006009519100189, 'acc': 0.6932515337423313, 'eod': 0.1432507038116455, 'train_loss': 0.6380364757317764, 'id': 8} 815\n",
      "{'indfair': 1.4076769948005676, 'acc': 0.6830357142857143, 'eod': nan, 'train_loss': 0.6352867313793727, 'id': 9} 224\n",
      "{'indfair': 0.8938933610916138, 'acc': 0.6554809843400448, 'eod': nan, 'train_loss': 0.6325978551592145, 'id': 3} 447\n",
      "{'indfair': 0.47334228456020355, 'acc': 0.6405228758169934, 'eod': nan, 'train_loss': 0.6418558776378631, 'id': 4} 306\n",
      "{'indfair': 0.6356741487979889, 'acc': 0.69140625, 'eod': 0.0520833358168602, 'train_loss': 0.5540600948863559, 'id': 7} 258\n",
      "============= LOGGG WEIGHT RESULTS\n",
      "[5, 0, 6, 1, 2, 8, 9, 3, 4, 7]\n",
      "{0: 0.18071788040021572, 9: -0.003438017048850301, 8: 0.2818233012380154, 1: 0.021809703437172312, 4: 0.07744838958706073, 5: 0.07279054009599414, 6: 0.01124907323433373, 3: 0.14453019566555336, 7: 0.13485908153271534, 2: 0.07820985185778964}\n",
      "Test Accuracy: 0.6720647773279352 - Test Loss: 20.125912505846756 - EOD: 0.20494157075881958 - IndFair: 0.40790942311286926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
      "\u001b[92mINFO \u001b[0m:      \n",
      "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
      "\u001b[92mINFO \u001b[0m:      Run finished 10 round(s) in 56.66s\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 19.321498603787564\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 17.977108918770366\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 18.290612224692094\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 18.517615220185693\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 16.996221114865016\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 6: 17.126661344569452\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 7: 18.422375266865906\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 8: 17.258604381012983\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 9: 17.42877509300135\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 10: 17.533226886084154\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 0: 25.511822222135006\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 1: 20.874681086112293\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 2: 20.18538178388889\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 3: 20.10611885633224\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 4: 20.09442985516328\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 5: 20.010937603620384\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 6: 20.123105781200604\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 7: 19.963842173417408\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 8: 19.99332001270392\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 9: 19.99785047922379\n",
      "\u001b[92mINFO \u001b[0m:      \t\tround 10: 20.125912505846756\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, distributed, evaluate):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'federated_evaluate_accuracy': [(1, 0.5500969618616678),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                 (2, 0.593006993006993),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                 (3, 0.5790262172284644),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                 (4, 0.5994815294880104),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                 (5, 0.6011560693641619),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                 (6, 0.5982142857142857),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                 (7, 0.6387981711299804),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                 (8, 0.6565176022835395),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                 (9, 0.5783251231527093),\n",
      "\u001b[92mINFO \u001b[0m:      \t                                 (10, 0.6617647058823529)]}\n",
      "\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n",
      "\u001b[92mINFO \u001b[0m:      \t{'centralized_accuracy': [(0, 0.5562753036437247),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (1, 0.5417004048582996),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (2, 0.5838056680161944),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (3, 0.5862348178137652),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (4, 0.605668016194332),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (5, 0.6283400809716599),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (6, 0.594331983805668),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (7, 0.6283400809716599),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (8, 0.6639676113360324),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (9, 0.5797570850202429),\n",
      "\u001b[92mINFO \u001b[0m:      \t                          (10, 0.6720647773279352)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'eod': [(0, 0.07481992244720459),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (1, -0.006097560748457909),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (2, 0.09194758534431458),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (3, 0.08585002273321152),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (4, 0.14469224959611893),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (5, 0.14575137197971344),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (6, 0.08988984674215317),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (7, 0.14575137197971344),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (8, 0.20068994164466858),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (9, 0.08542637526988983),\n",
      "\u001b[92mINFO \u001b[0m:      \t         (10, 0.20494157075881958)],\n",
      "\u001b[92mINFO \u001b[0m:      \t 'indf': [(0, 0.5877457112073898),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (1, 0.05039329081773758),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (2, 0.1680736318230629),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (3, 0.18071679770946503),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (4, 0.21142560988664627),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (5, 0.26947323977947235),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (6, 0.15418964251875877),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (7, 0.2882625609636307),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (8, 0.3448680192232132),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (9, 0.14665638655424118),\n",
      "\u001b[92mINFO \u001b[0m:      \t          (10, 0.40790942311286926)]}\n",
      "\u001b[92mINFO \u001b[0m:      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=259346)\u001b[0m Skipping batch with single class.\n",
      "\u001b[36m(ClientAppActor pid=259349)\u001b[0m Avg Train Loss: 0.6352867313793727 - EOD: nan - Accuracy: 0.6830357142857143 - Ind Fair: 1.4076769948005676\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259347)\u001b[0m Avg Train Loss: 0.6380364757317764 - EOD: 0.1432507038116455 - Accuracy: 0.6932515337423313 - Ind Fair: 0.7006009519100189\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259349)\u001b[0m Test Accuracy: 0.7183098591549296 - Test Loss: 11.671034435431162 - EOD: nan - IndFair: 0.39515921473503113\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259350)\u001b[0m Test Accuracy: 0.632183908045977 - Test Loss: 18.11169668038686 - EOD: 0.6857142746448517 - IndFair: 0.7766162157058716\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ClientAppActor pid=259346)\u001b[0m /home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (61) was not satisfied for alpha ([0.5]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\u001b[32m [repeated 111x across cluster]\u001b[0m\n",
      "\u001b[36m(ClientAppActor pid=259346)\u001b[0m   warnings.warn(\u001b[32m [repeated 111x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import flwr as fl\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import Context\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from custom_flwr.server_app import server_fn as server_fn_custom\n",
    "from custom_flwr.client_app import client_fn as client_fn_custom\n",
    "\n",
    "DEVICE = torch.device('cpu')\n",
    "\n",
    "def server_fn(context: Context):\n",
    "    context.run_config = {\n",
    "        'num-server-rounds' : 10,\n",
    "        'fraction-fit': 1,\n",
    "        'fraction-evaluate': 1,\n",
    "        'local-epochs': 2,\n",
    "        'server-device': str(DEVICE),\n",
    "        'use-wandb': False\n",
    "    }\n",
    "    return server_fn_custom(context)\n",
    "\n",
    "def client_fn(context: Context):\n",
    "    return client_fn_custom(context)\n",
    "\n",
    "client = ClientApp(client_fn=client_fn)\n",
    "server = ServerApp(server_fn=server_fn)\n",
    "\n",
    "\n",
    "backend_config = {\"client_resources\": None}\n",
    "NUM_PARTITIONS = 10\n",
    "run_simulation(\n",
    "    server_app=server,\n",
    "    client_app=client,\n",
    "    num_supernodes=NUM_PARTITIONS,\n",
    "    backend_config=backend_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hi"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
