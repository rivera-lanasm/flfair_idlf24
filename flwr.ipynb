{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Make sure you're on Python > 3.8\n","# !pip install -r requirements.txt --quiet"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T12:17:46.659679Z","iopub.status.busy":"2024-10-25T12:17:46.658663Z","iopub.status.idle":"2024-10-25T12:17:46.667484Z","shell.execute_reply":"2024-10-25T12:17:46.666371Z","shell.execute_reply.started":"2024-10-25T12:17:46.659634Z"},"trusted":true},"outputs":[],"source":["from collections import OrderedDict\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","from sklearn.model_selection import train_test_split\n","\n","import flwr as fl\n","from flwr.simulation import run_simulation\n","from flwr.client import Client, ClientApp, NumPyClient\n","from flwr.common import Context\n","from flwr.server import ServerApp, ServerConfig, ServerAppComponents"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T11:58:45.930449Z","iopub.status.busy":"2024-10-25T11:58:45.930029Z","iopub.status.idle":"2024-10-25T11:58:45.935361Z","shell.execute_reply":"2024-10-25T11:58:45.934262Z","shell.execute_reply.started":"2024-10-25T11:58:45.930408Z"},"trusted":true},"outputs":[],"source":["DEVICE = torch.device('cpu')"]},{"cell_type":"markdown","metadata":{},"source":["## Load and Pre Process Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T12:14:13.068868Z","iopub.status.busy":"2024-10-25T12:14:13.068133Z","iopub.status.idle":"2024-10-25T12:14:16.196420Z","shell.execute_reply":"2024-10-25T12:14:16.195111Z","shell.execute_reply.started":"2024-10-25T12:14:13.068823Z"},"trusted":true},"outputs":[],"source":["!mkdir '.kaggle'\n","!mkdir '.kaggle/data'\n","\n","with open(\".kaggle/kaggle.json\", 'a+') as f:\n","    f.write('{\"username\":\"rajaxarcmu\",\"key\":\"68d40c5e38e1c786ab57736bc5c9b2cb\"}')\n","    \n","!chmod 600 '.kaggle/kaggle.json'\n","!kaggle datasets download -d 'danofer/compass'\n","!unzip -qo compass.zip -d '.kaggle/data'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T12:14:32.021319Z","iopub.status.busy":"2024-10-25T12:14:32.020880Z","iopub.status.idle":"2024-10-25T12:14:33.032459Z","shell.execute_reply":"2024-10-25T12:14:33.031476Z","shell.execute_reply.started":"2024-10-25T12:14:32.021279Z"},"trusted":true},"outputs":[],"source":["!ls .kaggle/data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T12:06:41.699264Z","iopub.status.busy":"2024-10-25T12:06:41.698569Z","iopub.status.idle":"2024-10-25T12:06:41.719649Z","shell.execute_reply":"2024-10-25T12:06:41.718737Z","shell.execute_reply.started":"2024-10-25T12:06:41.699226Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv('.kaggle/data/propublicaCompassRecividism_data_fairml.csv/propublica_data_for_fairml.csv')\n","print(df.shape)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["df['caucasian'] = ((df['African_American'] + df['Asian'] + df['Hispanic'] + df['Native_American'] + df['Other']) == 0).astype(int)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T13:01:23.411628Z","iopub.status.busy":"2024-10-25T13:01:23.410876Z","iopub.status.idle":"2024-10-25T13:01:23.417053Z","shell.execute_reply":"2024-10-25T13:01:23.416069Z","shell.execute_reply.started":"2024-10-25T13:01:23.411584Z"},"trusted":true},"outputs":[],"source":["NUM_CLIENTS = 10\n","# REPRESENTS SILO'D ORGANIZATIONS"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from datasets import Dataset\n","from flwr_datasets.partitioner import DirichletPartitioner"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T12:48:53.225931Z","iopub.status.busy":"2024-10-25T12:48:53.225480Z","iopub.status.idle":"2024-10-25T12:48:53.279015Z","shell.execute_reply":"2024-10-25T12:48:53.277955Z","shell.execute_reply.started":"2024-10-25T12:48:53.225858Z"},"trusted":true},"outputs":[],"source":["trainset, testset = train_test_split(df, test_size=0.2)\n","batch_size = 32\n","\n","ds = Dataset.from_pandas(trainset)\n","\n","partitioner = DirichletPartitioner(\n","    num_partitions=NUM_CLIENTS,\n","    partition_by=\"caucasian\",\n","    alpha=0.5,\n","    min_partition_size=(len(trainset) // (4 * NUM_CLIENTS)),\n","    self_balancing=True,\n","    shuffle=True\n",")\n","\n","partitioner.dataset = ds\n","datasets = []\n","for i in range(NUM_CLIENTS):\n","    curr_partition = partitioner.load_partition(i)\n","    datasets.append(curr_partition.to_pandas())\n","\n","train_loaders = []\n","val_loaders = []\n","\n","feature_columns = ['Number_of_Priors', 'score_factor','Age_Above_FourtyFive', 'Age_Below_TwentyFive', 'Misdemeanor']\n","\n","for ds in datasets:\n","    train_x = ds[feature_columns].values\n","    train_y = ds['Two_yr_Recidivism'].values\n","    sensitive_feature = ds['caucasian'].values\n","\n","    train_x, val_x, train_y, val_y, sensitive_train, sensitive_val = train_test_split(\n","        train_x, train_y, sensitive_feature, test_size=0.25, shuffle=True, stratify=train_y, random_state=42\n","    )\n","    \n","    train_x_tensor = torch.from_numpy(train_x).float()\n","    train_y_tensor = torch.from_numpy(train_y).float()\n","    sensitive_train_tensor = torch.from_numpy(sensitive_train).float()\n","\n","    valid_x_tensor = torch.from_numpy(val_x).float()\n","    valid_y_tensor = torch.from_numpy(val_y).float()\n","    sensitive_val_tensor = torch.from_numpy(sensitive_val).float()\n","\n","    # Create TensorDataset and DataLoader, including the sensitive attribute\n","    train_dataset = TensorDataset(train_x_tensor, train_y_tensor, sensitive_train_tensor)\n","    valid_dataset = TensorDataset(valid_x_tensor, valid_y_tensor, sensitive_val_tensor)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(valid_dataset, batch_size=batch_size)\n","\n","    train_loaders.append(train_loader)\n","    val_loaders.append(val_loader)\n","\n","# For test data\n","test_x = testset[feature_columns].values\n","test_y = testset['Two_yr_Recidivism'].values\n","sensitive_test = testset['caucasian'].values\n","\n","test_x_tensor = torch.from_numpy(test_x).float()\n","test_y_tensor = torch.from_numpy(test_y).float()\n","sensitive_test_tensor = torch.from_numpy(sensitive_test).float()\n","\n","test_dataset = TensorDataset(test_x_tensor, test_y_tensor, sensitive_test_tensor)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["## Client Model Architecture"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T13:00:19.279443Z","iopub.status.busy":"2024-10-25T13:00:19.278708Z","iopub.status.idle":"2024-10-25T13:00:19.294747Z","shell.execute_reply":"2024-10-25T13:00:19.293786Z","shell.execute_reply.started":"2024-10-25T13:00:19.279390Z"},"trusted":true},"outputs":[],"source":["class BaselineNN(nn.Module):\n","    def __init__(self):\n","        super(BaselineNN, self).__init__()\n","        self.fc1 = nn.Linear(5, 16)\n","        self.fc2 = nn.Linear(16, 8)\n","        self.fc3 = nn.Linear(8, 1)\n","        \n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        x = torch.sigmoid(self.fc3(x))\n","        return x\n","\n","def compute_eod(preds, labels, sensitive_feature):\n","    preds_binary = (preds >= 0.5).float()\n","    y_true_mask = (labels == 1).view(-1)\n","\n","    p_a0 = preds_binary[y_true_mask & (sensitive_feature == 0)].mean().item()\n","    p_a1 = preds_binary[y_true_mask & (sensitive_feature == 1)].mean().item()\n","\n","    eod = p_a0 - p_a1\n","    return eod\n","\n","def train(net, trainloader, epochs, verbose=True):\n","    \"\"\"\n","    Train Network on Training Set\n","    \"\"\"\n","    criterion = nn.BCELoss()\n","    optimizer = optim.Adam(net.parameters())\n","    net.train()\n","    for epoch in range(epochs):\n","        correct, total, epoch_loss = 0, 0, 0.0\n","        all_preds, all_labels, all_sensitives = [], [], []\n","        \n","        for inputs, labels, sensitive_features in trainloader:\n","            inputs, labels, sensitive_features = inputs.to(DEVICE), labels.to(DEVICE), sensitive_features.to(DEVICE)\n","            optimizer.zero_grad()\n","            outputs = net(inputs)\n","            labels = labels.view(-1, 1)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            epoch_loss += loss.item() * inputs.size(0)\n","            predicted = (outputs >= 0.5).float()\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            \n","            # Append predictions and sensitive data for EOD computation\n","            all_preds.append(outputs.detach().cpu())\n","            all_labels.append(labels.detach().cpu())\n","            all_sensitives.append(sensitive_features.cpu())\n","        \n","        # Compute EOD at the end of the epoch\n","        all_preds = torch.cat(all_preds)\n","        all_labels = torch.cat(all_labels)\n","        all_sensitives = torch.cat(all_sensitives)\n","        \n","        eod = compute_eod(all_preds, all_labels, all_sensitives)\n","        \n","        epoch_loss /= len(trainloader.dataset)\n","        epoch_acc = correct / total\n","        if verbose:\n","            print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f} - Acc: {epoch_acc:.4f} - EOD: {eod:.4f}\")\n","\n","def test(net, testloader, verbose=True):\n","    criterion = nn.BCELoss()\n","    net.eval()\n","    correct, total, loss = 0, 0, 0.0\n","    all_preds, all_labels, all_sensitives = [], [], []\n","    \n","    with torch.no_grad():\n","        for inputs, labels, sensitive_features in testloader:\n","            inputs, labels, sensitive_features = inputs.to(DEVICE), labels.to(DEVICE), sensitive_features.to(DEVICE)\n","            outputs = net(inputs)\n","            labels = labels.view(-1, 1)\n","            loss += criterion(outputs, labels).item() * inputs.size(0)\n","            predicted = (outputs >= 0.5).float()\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","            \n","            # Append predictions and sensitive data for EOD computation\n","            all_preds.append(outputs.detach().cpu())\n","            all_labels.append(labels.detach().cpu())\n","            all_sensitives.append(sensitive_features.cpu())\n","    \n","    # Compute EOD at the end of testing\n","    all_preds = torch.cat(all_preds)\n","    all_labels = torch.cat(all_labels)\n","    all_sensitives = torch.cat(all_sensitives)\n","    \n","    eod = compute_eod(all_preds, all_labels, all_sensitives)\n","    \n","    loss /= len(testloader.dataset)\n","    acc = correct / total\n","    if verbose:\n","        print(f\"Test Loss: {loss:.4f} - Acc: {acc:.4f} - EOD: {eod:.4f}\")\n","    return loss, acc, eod"]},{"cell_type":"markdown","metadata":{},"source":["# Centralized Learning"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T13:03:14.741347Z","iopub.status.busy":"2024-10-25T13:03:14.740928Z","iopub.status.idle":"2024-10-25T13:03:14.747485Z","shell.execute_reply":"2024-10-25T13:03:14.746493Z","shell.execute_reply.started":"2024-10-25T13:03:14.741306Z"},"trusted":true},"outputs":[],"source":["model = BaselineNN()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T13:03:15.061229Z","iopub.status.busy":"2024-10-25T13:03:15.060802Z","iopub.status.idle":"2024-10-25T13:03:16.695498Z","shell.execute_reply":"2024-10-25T13:03:16.694330Z","shell.execute_reply.started":"2024-10-25T13:03:15.061191Z"},"trusted":true},"outputs":[],"source":["for i in range(NUM_CLIENTS):\n","    train_loader = train_loaders[i]\n","    val_loader = val_loaders[i]\n","    model = model.to(DEVICE)\n","    epochs = 10\n","\n","    for epoch in range(epochs):\n","        train(model, train_loader, 1, verbose=False)\n","        loss, acc, eod = test(model, val_loader, verbose=False)\n","\n","    loss, acc, eod = test(model, test_loader, verbose=False)\n","    print(f\"Client {i} - Test Loss: {loss:.4f} - Acc: {acc:.4f} - EOD: {eod:.4f}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Federated Learning with Flower"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-25T13:10:12.128000Z","iopub.status.busy":"2024-10-25T13:10:12.127587Z","iopub.status.idle":"2024-10-25T13:10:12.134115Z","shell.execute_reply":"2024-10-25T13:10:12.132993Z","shell.execute_reply.started":"2024-10-25T13:10:12.127954Z"},"trusted":true},"outputs":[],"source":["import flwr as fl\n","from flwr.simulation import run_simulation\n","from flwr.client import Client, ClientApp, NumPyClient\n","from flwr.common import Context\n","from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n","\n","from collections import OrderedDict\n","import numpy as np\n","import pandas as pd\n","import torch\n","\n","from custom_flwr.server_app import server_fn as server_fn_custom\n","from custom_flwr.client_app import client_fn as client_fn_custom\n","\n","DEVICE = torch.device('cpu')\n","\n","def server_fn(context: Context):\n","    context.run_config = {\n","        'num-server-rounds' : 10,\n","        'fraction-fit': 1,\n","        'fraction-evaluate': 1,\n","        'local-epochs': 2,\n","        'server-device': str(DEVICE),\n","        'use-wandb': False\n","    }\n","    return server_fn_custom(context)\n","\n","def client_fn(context: Context):\n","    return client_fn_custom(context)\n","\n","client = ClientApp(client_fn=client_fn)\n","server = ServerApp(server_fn=server_fn)\n","\n","\n","backend_config = {\"client_resources\": None}\n","NUM_PARTITIONS = 10\n","run_simulation(\n","    server_app=server,\n","    client_app=client,\n","    num_supernodes=NUM_PARTITIONS,\n","    backend_config=backend_config,\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (123) was not satisfied for alpha ([0.5]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n","  warnings.warn(\n","/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (123) was not satisfied for alpha ([0.5]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n","  warnings.warn(\n","/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (123) was not satisfied for alpha ([0.5]) after 2 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n","  warnings.warn(\n","/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (123) was not satisfied for alpha ([0.5]) after 3 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n","  warnings.warn(\n","/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (123) was not satisfied for alpha ([0.5]) after 4 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n","  warnings.warn(\n","/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (123) was not satisfied for alpha ([0.5]) after 5 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n","  warnings.warn(\n","/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (123) was not satisfied for alpha ([0.5]) after 6 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n","  warnings.warn(\n","\u001b[92mINFO \u001b[0m:      Starting Flower ServerApp, config: num_rounds=10, no round_timeout\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [INIT]\n","\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n","\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n","\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 21.056317716072765, {'centralized_accuracy': 0.6283400809716599, 'eod': 0.15449416637420654}\n","\u001b[92mINFO \u001b[0m:      \n","\u001b[92mINFO \u001b[0m:      [ROUND 1]\n"]},{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.6283400809716599 - Test Loss: 21.056317716072765 - EOD: 0.15449416637420654\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 10)\n","\u001b[36m(ClientAppActor pid=1900756)\u001b[0m /home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (123) was not satisfied for alpha ([0.5]) after 0 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n","\u001b[36m(ClientAppActor pid=1900756)\u001b[0m   warnings.warn(\n","\u001b[36m(ClientAppActor pid=1900756)\u001b[0m /home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (123) was not satisfied for alpha ([0.5]) after 1 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n","\u001b[36m(ClientAppActor pid=1900756)\u001b[0m   warnings.warn(\n","\u001b[36m(ClientAppActor pid=1900756)\u001b[0m /home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (123) was not satisfied for alpha ([0.5]) after 2 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n","\u001b[36m(ClientAppActor pid=1900756)\u001b[0m   warnings.warn(\n","\u001b[36m(ClientAppActor pid=1900756)\u001b[0m /home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (123) was not satisfied for alpha ([0.5]) after 3 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n","\u001b[36m(ClientAppActor pid=1900756)\u001b[0m   warnings.warn(\n","\u001b[36m(ClientAppActor pid=1900756)\u001b[0m /home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (123) was not satisfied for alpha ([0.5]) after 4 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n","\u001b[36m(ClientAppActor pid=1900756)\u001b[0m   warnings.warn(\n","\u001b[36m(ClientAppActor pid=1900756)\u001b[0m /home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (123) was not satisfied for alpha ([0.5]) after 5 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n","\u001b[36m(ClientAppActor pid=1900756)\u001b[0m   warnings.warn(\n","\u001b[36m(ClientAppActor pid=1900756)\u001b[0m /home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (123) was not satisfied for alpha ([0.5]) after 6 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\n","\u001b[36m(ClientAppActor pid=1900756)\u001b[0m   warnings.warn(\n","\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n","\u001b[91mERROR \u001b[0m:     ServerApp thread raised an exception: 'id'\n","\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n","  File \"/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr/simulation/run_simulation.py\", line 336, in server_th_with_start_checks\n","    run_server_app(\n","  File \"/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr/server/run_serverapp.py\", line 88, in run\n","    server_app(driver=driver, context=context)\n","  File \"/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr/server/server_app.py\", line 120, in __call__\n","    start_driver(\n","  File \"/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr/server/compat/app.py\", line 87, in start_driver\n","    hist = run_fl(\n","  File \"/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr/server/server.py\", line 492, in run_fl\n","    hist, elapsed_time = server.fit(\n","  File \"/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr/server/server.py\", line 115, in fit\n","    res_fit = self.fit_round(\n","  File \"/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr/server/server.py\", line 251, in fit_round\n","    ] = self.strategy.aggregate_fit(server_round, results, failures)\n","  File \"/home/rivlanm/cmu/dlintro/flfair_idlf24/custom_flwr/idl24_FairFed.py\", line 318, in aggregate_fit\n","    weights_results = [\n","  File \"/home/rivlanm/cmu/dlintro/flfair_idlf24/custom_flwr/idl24_FairFed.py\", line 321, in <listcomp>\n","    fit_res.metrics['id'],\n","  File \"/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr/common/record/typeddict.py\", line 60, in __getitem__\n","    return cast(Dict[K, V], self.__dict__[\"_data\"])[item]\n","KeyError: 'id'\n","\n","Exception in thread Thread-4:\n","Traceback (most recent call last):\n","  File \"/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n","    self.run()\n","  File \"/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 766, in run_closure\n","    _threading_Thread_run(self)\n","  File \"/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr/simulation/run_simulation.py\", line 336, in server_th_with_start_checks\n","    run_server_app(\n","  File \"/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr/server/run_serverapp.py\", line 88, in run\n","    server_app(driver=driver, context=context)\n","  File \"/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr/server/server_app.py\", line 120, in __call__\n","    start_driver(\n","  File \"/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr/server/compat/app.py\", line 87, in start_driver\n","    hist = run_fl(\n","  File \"/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr/server/server.py\", line 492, in run_fl\n","    hist, elapsed_time = server.fit(\n","  File \"/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr/server/server.py\", line 115, in fit\n","    res_fit = self.fit_round(\n","  File \"/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr/server/server.py\", line 251, in fit_round\n","    ] = self.strategy.aggregate_fit(server_round, results, failures)\n","  File \"/home/rivlanm/cmu/dlintro/flfair_idlf24/custom_flwr/idl24_FairFed.py\", line 318, in aggregate_fit\n","    weights_results = [\n","  File \"/home/rivlanm/cmu/dlintro/flfair_idlf24/custom_flwr/idl24_FairFed.py\", line 321, in <listcomp>\n","    fit_res.metrics['id'], \n","  File \"/home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr/common/record/typeddict.py\", line 60, in __getitem__\n","    return cast(Dict[K, V], self.__dict__[\"_data\"])[item]\n","KeyError: 'id'\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[36m(ClientAppActor pid=1900756)\u001b[0m Avg Train Loss: 0.650560728708903 - EOD: 0.1979595273733139 - Accuracy: 0.6497890295358649\n","\u001b[36m(ClientAppActor pid=1900755)\u001b[0m Avg Train Loss: 0.7148471623659134 - EOD: 0.06833335757255554 - Accuracy: 0.5689655172413793\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[36m(ClientAppActor pid=1900755)\u001b[0m /home/rivlanm/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr_datasets/partitioner/dirichlet_partitioner.py:300: UserWarning: The specified min_partition_size (123) was not satisfied for alpha ([0.5]) after 6 attempts at sampling from the Dirichlet distribution. The probability sampling from the Dirichlet distribution will be repeated. Note: This is not a desired behavior. It is recommended to adjust the alpha or min_partition_size instead. Generating partitions by sampling from a list of very wide range of alpha values can be hard to achieve. Try reducing the range between maximum (0.5) and minimum alpha (0.5) values or increasing all the values.\u001b[32m [repeated 21x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n","\u001b[36m(ClientAppActor pid=1900755)\u001b[0m   warnings.warn(\u001b[32m [repeated 21x across cluster]\u001b[0m\n"]},{"ename":"RuntimeError","evalue":"Exception in ServerApp thread","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m backend_config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclient_resources\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[1;32m      2\u001b[0m NUM_PARTITIONS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrun_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_app\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_app\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_supernodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_PARTITIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr/simulation/run_simulation.py:291\u001b[0m, in \u001b[0;36mrun_simulation\u001b[0;34m(server_app, client_app, num_supernodes, backend_name, backend_config, enable_tf_gpu_growth, verbose_logging)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m enable_tf_gpu_growth:\n\u001b[1;32m    283\u001b[0m     warn_deprecated_feature_with_example(\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing `enable_tf_gpu_growth=True` is deprecated.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    285\u001b[0m         example_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstead, set the `TF_FORCE_GPU_ALLOW_GROWTH` environment \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mflwr.simulation.run_simulationt(...)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    289\u001b[0m     )\n\u001b[0;32m--> 291\u001b[0m \u001b[43m_run_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_supernodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_supernodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_app\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_app\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_app\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_app\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_tf_gpu_growth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_tf_gpu_growth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexit_event\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEventType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPYTHON_API_RUN_SIMULATION_LEAVE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr/simulation/run_simulation.py:558\u001b[0m, in \u001b[0;36m_run_simulation\u001b[0;34m(num_supernodes, exit_event, client_app, server_app, backend_name, backend_config, client_app_attr, server_app_attr, server_app_run_config, app_dir, flwr_dir, run, enable_tf_gpu_growth, delay_start, verbose_logging, is_app)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m asyncio_loop_running:\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;66;03m# Set logger propagation to False to prevent duplicated log output in Colab.\u001b[39;00m\n\u001b[1;32m    556\u001b[0m     logger \u001b[38;5;241m=\u001b[39m set_logger_propagation(logger, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 558\u001b[0m \u001b[43m_main_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/idlf24/lib/python3.8/site-packages/flwr/simulation/run_simulation.py:453\u001b[0m, in \u001b[0;36m_main_loop\u001b[0;34m(num_supernodes, backend_name, backend_config_stream, app_dir, is_app, enable_tf_gpu_growth, run, exit_event, delay_start, flwr_dir, client_app, client_app_attr, server_app, server_app_attr, server_app_run_config)\u001b[0m\n\u001b[1;32m    451\u001b[0m         serverapp_th\u001b[38;5;241m.\u001b[39mjoin()\n\u001b[1;32m    452\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m server_app_thread_has_exception\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[0;32m--> 453\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException in ServerApp thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    455\u001b[0m log(DEBUG, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopping Simulation Engine now.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mRuntimeError\u001b[0m: Exception in ServerApp thread"]}],"source":[]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["from custom_flwr.idl24_FairFed import CustomFairFed as FairFed"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"idlf24","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.19"}},"nbformat":4,"nbformat_minor":4}
