{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import flwr as fl\n",
    "from flwr.simulation import run_simulation\n",
    "from flwr.client import Client, ClientApp, NumPyClient\n",
    "from flwr.common import Context\n",
    "from flwr.server import ServerApp, ServerConfig, ServerAppComponents\n",
    "\n",
    "from datasets import Dataset\n",
    "from flwr_datasets.partitioner import DirichletPartitioner\n",
    "\n",
    "DEVICE = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # flower config \n",
    "    \"num_clients\":10,\n",
    "    # train data \n",
    "    \"train_test_split\":.2,\n",
    "    # client model\n",
    "    \"batch_size\":32,\n",
    "\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Pre Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir '.kaggle'\n",
    "!mkdir '.kaggle/data'\n",
    "\n",
    "with open(\".kaggle/kaggle.json\", 'a+') as f:\n",
    "    f.write('{\"username\":\"rajaxarcmu\",\"key\":\"68d40c5e38e1c786ab57736bc5c9b2cb\"}')\n",
    "    \n",
    "!chmod 600 '.kaggle/kaggle.json'\n",
    "!kaggle datasets download -d 'danofer/compass'\n",
    "!unzip -qo compass.zip -d '.kaggle/data'\n",
    "\n",
    "!ls .kaggle/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('.kaggle/data/propublicaCompassRecividism_data_fairml.csv/propublica_data_for_fairml.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['caucasian'] = ((df['African_American'] + df['Asian'] + df['Hispanic'] + df['Native_American'] + df['Other']) == 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Data Loader\n",
    "- including data heterogeneity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/test split \n",
    "trainset, testset = train_test_split(df, test_size=0.2)\n",
    "\n",
    "# train data set\n",
    "ds = Dataset.from_pandas(trainset)\n",
    "\n",
    "# Flower Partitioner\n",
    "partitioner = DirichletPartitioner(\n",
    "    num_partitions=config[\"num_clients\"],\n",
    "    partition_by=\"caucasian\",\n",
    "    alpha=0.5,\n",
    "    min_partition_size=(len(trainset) // (4 * config[\"num_clients\"])),\n",
    "    self_balancing=True,\n",
    "    shuffle=True)\n",
    "\n",
    "# populate train partitioned datasets \n",
    "partitioner.dataset = ds\n",
    "datasets = []\n",
    "for i in range(config[\"num_clients\"]):\n",
    "    curr_partition = partitioner.load_partition(i)\n",
    "    datasets.append(curr_partition.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate train/test data loaders \n",
    "train_loaders = []\n",
    "val_loaders = []\n",
    "\n",
    "feature_columns = ['Number_of_Priors', 'score_factor','Age_Above_FourtyFive', 'Age_Below_TwentyFive', 'Misdemeanor']\n",
    "\n",
    "for ds in datasets:\n",
    "    train_x = ds[feature_columns].values\n",
    "    train_y = ds['Two_yr_Recidivism'].values\n",
    "    sensitive_feature = ds['caucasian'].values\n",
    "\n",
    "    train_x, val_x, train_y, val_y, sensitive_train, sensitive_val = train_test_split(\n",
    "        train_x, train_y, sensitive_feature, test_size=0.25, shuffle=True, stratify=train_y, random_state=42\n",
    "    )\n",
    "    \n",
    "    train_x_tensor = torch.from_numpy(train_x).float()\n",
    "    train_y_tensor = torch.from_numpy(train_y).float()\n",
    "    sensitive_train_tensor = torch.from_numpy(sensitive_train).float()\n",
    "\n",
    "    valid_x_tensor = torch.from_numpy(val_x).float()\n",
    "    valid_y_tensor = torch.from_numpy(val_y).float()\n",
    "    sensitive_val_tensor = torch.from_numpy(sensitive_val).float()\n",
    "\n",
    "    # Create TensorDataset and DataLoader, including the sensitive attribute\n",
    "    train_dataset = TensorDataset(train_x_tensor, train_y_tensor, sensitive_train_tensor)\n",
    "    valid_dataset = TensorDataset(valid_x_tensor, valid_y_tensor, sensitive_val_tensor)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    val_loader = DataLoader(valid_dataset, batch_size=config[\"batch_size\"])\n",
    "\n",
    "    train_loaders.append(train_loader)\n",
    "    val_loaders.append(val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build test data set\n",
    "test_x = testset[feature_columns].values\n",
    "test_y = testset['Two_yr_Recidivism'].values\n",
    "sensitive_test = testset['caucasian'].values\n",
    "\n",
    "test_x_tensor = torch.from_numpy(test_x).float()\n",
    "test_y_tensor = torch.from_numpy(test_y).float()\n",
    "sensitive_test_tensor = torch.from_numpy(sensitive_test).float()\n",
    "\n",
    "test_dataset = TensorDataset(test_x_tensor, test_y_tensor, sensitive_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "idlf24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
